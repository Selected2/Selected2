{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "the6Classproposed1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#6 class proposed 1"
      ],
      "metadata": {
        "id": "SYzv9WThHuAE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xbyzq0J2Bqb",
        "outputId": "a35847fd-5f49-4bf6-b47c-c4655d502ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 224, 224 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last"
      ],
      "metadata": {
        "id": "0G5Ei9TI61jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator()  \n",
        "valid_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator1 = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Train',\n",
        "        classes = ['motorbike&airplan','flower&car','person&dog'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')\n",
        "\n",
        "valid_generator1 = valid_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Validate',\n",
        "        classes = ['motorbike&airplan','flower&car','person&dog'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')\n",
        "\n",
        "train_generator21 = train_datagen.flow_from_directory(\n",
        "       '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Train',\n",
        "        classes = ['motorbike','airplane'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')\n",
        "\n",
        "valid_generator21 = valid_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Validate',\n",
        "        classes = ['motorbike','airplane'], \n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')\n",
        "\n",
        "train_generator22 = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Train',\n",
        "        classes = ['flower','car'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')\n",
        "\n",
        "valid_generator22 = valid_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Validate',\n",
        "        classes = ['flower','car'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')\n",
        "\n",
        "train_generator23 = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Train',\n",
        "        classes = ['person','dog'],\n",
        "        target_size=(img_rows, img_cols),batch_size=16,class_mode='binary')\n",
        "\n",
        "valid_generator23 = valid_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Validate',\n",
        "        classes = ['person','dog'],\n",
        "        target_size=(img_rows, img_cols),batch_size=16,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpPvtWIv6_1A",
        "outputId": "3e78d4fd-1b11-41a1-c92d-929607d839eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2298 images belonging to 3 classes.\n",
            "Found 1063 images belonging to 3 classes.\n",
            "Found 766 images belonging to 2 classes.\n",
            "Found 351 images belonging to 2 classes.\n",
            "Found 766 images belonging to 2 classes.\n",
            "Found 356 images belonging to 2 classes.\n",
            "Found 766 images belonging to 2 classes.\n",
            "Found 356 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model1 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)\n",
        "base_model21 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)\n",
        "base_model22 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)\n",
        "base_model23 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)"
      ],
      "metadata": {
        "id": "Cb4VM-l27Ajr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4fb58d-4f50-4cc1-bb94-950227efbe30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model1.layers:   layer.trainable = False\n",
        "for layer in base_model21.layers:   layer.trainable = False\n",
        "for layer in base_model22.layers:   layer.trainable = False\n",
        "for layer in base_model23.layers:   layer.trainable = False"
      ],
      "metadata": {
        "id": "1-C57mFk7DAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model1.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "preds = tf.keras.layers.Dense(3, activation ='softmax')(x)\n",
        "model1 = tf.keras.models.Model(inputs=base_model1.input, outputs=preds)\n",
        "\n",
        "x = base_model21.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)\n",
        "model21 = tf.keras.models.Model(inputs=base_model21.input, outputs=preds)\n",
        "\n",
        "\n",
        "x = base_model22.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)\n",
        "model22 = tf.keras.models.Model(inputs=base_model22.input, outputs=preds)\n",
        "\n",
        "x = base_model23.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)   # the only diff\n",
        "model23 = tf.keras.models.Model(inputs=base_model23.input, outputs=preds)"
      ],
      "metadata": {
        "id": "QozywFKS7Fs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model21.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model22.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model23.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "99WfmJ2B7Hhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb1= tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")\n",
        "\n",
        "cb2= tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")\n",
        "\n",
        "cb3= tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")\n",
        "\n",
        "cb4= tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "hd_J1Fo_8p1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(\n",
        "      train_generator1,\n",
        "      steps_per_epoch=train_generator1.n//train_generator1.batch_size,\n",
        "      epochs=25,\n",
        "      validation_data=valid_generator1,callbacks=[cb1],\n",
        "      validation_steps=25)\n",
        "\n",
        "history = model21.fit(\n",
        "      train_generator21,\n",
        "      steps_per_epoch=train_generator21.n//train_generator21.batch_size,\n",
        "      epochs=25,\n",
        "      validation_data=valid_generator21,callbacks=[cb2],\n",
        "      validation_steps=10)\n",
        "\n",
        "history = model22.fit(\n",
        "      train_generator22,\n",
        "      steps_per_epoch=train_generator22.n//train_generator22.batch_size,\n",
        "      epochs=25,\n",
        "      validation_data=valid_generator22,callbacks=[cb3],\n",
        "      validation_steps=10)\n",
        "\n",
        "history = model23.fit(\n",
        "      train_generator23,\n",
        "      steps_per_epoch=train_generator23.n//train_generator23.batch_size,\n",
        "      epochs=25,\n",
        "      validation_data=valid_generator23,callbacks=[cb4],\n",
        "      validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XDZhxqk8tuR",
        "outputId": "f2c5e156-8689-4b1d-c669-3049699ec8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "71/71 [==============================] - 651s 9s/step - loss: 0.2017 - accuracy: 0.9519 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 2/25\n",
            "71/71 [==============================] - 52s 746ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "71/71 [==============================] - 22s 309ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
            "Epoch 4/25\n",
            "71/71 [==============================] - 15s 206ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
            "Epoch 5/25\n",
            "71/71 [==============================] - 12s 174ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 6/25\n",
            "71/71 [==============================] - 13s 180ms/step - loss: 1.5098e-05 - accuracy: 1.0000 - val_loss: 2.1854e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "71/71 [==============================] - 13s 186ms/step - loss: 5.5106e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 8/25\n",
            "71/71 [==============================] - 13s 180ms/step - loss: 3.1120e-06 - accuracy: 1.0000 - val_loss: 8.5255e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "71/71 [==============================] - 12s 173ms/step - loss: 1.9345e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 10/25\n",
            "71/71 [==============================] - 13s 182ms/step - loss: 1.2971e-06 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
            "Epoch 11/25\n",
            "71/71 [==============================] - 13s 186ms/step - loss: 9.0541e-07 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 12/25\n",
            "71/71 [==============================] - 12s 175ms/step - loss: 6.7586e-07 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
            "Epoch 13/25\n",
            "71/71 [==============================] - 13s 176ms/step - loss: 5.0559e-07 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 14/25\n",
            "71/71 [==============================] - 14s 190ms/step - loss: 3.9828e-07 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "Epoch 15/25\n",
            "71/71 [==============================] - 13s 184ms/step - loss: 3.1906e-07 - accuracy: 1.0000 - val_loss: 2.8062e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "71/71 [==============================] - 12s 173ms/step - loss: 2.6014e-07 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 17/25\n",
            "71/71 [==============================] - 13s 185ms/step - loss: 2.1474e-07 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 18/25\n",
            "71/71 [==============================] - 13s 185ms/step - loss: 1.5519e-07 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 19/25\n",
            "71/71 [==============================] - 12s 172ms/step - loss: 1.5803e-07 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 20/25\n",
            "71/71 [==============================] - 12s 175ms/step - loss: 1.3457e-07 - accuracy: 1.0000 - val_loss: 1.9131e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "71/71 [==============================] - 13s 187ms/step - loss: 1.1626e-07 - accuracy: 1.0000 - val_loss: 7.7686e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "71/71 [==============================] - 13s 180ms/step - loss: 1.0111e-07 - accuracy: 1.0000 - val_loss: 7.7473e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "71/71 [==============================] - 12s 174ms/step - loss: 8.9012e-08 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
            "Epoch 24/25\n",
            "71/71 [==============================] - 13s 182ms/step - loss: 7.8543e-08 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9987\n",
            "Epoch 25/25\n",
            "71/71 [==============================] - 13s 186ms/step - loss: 6.9968e-08 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
            "Epoch 1/25\n",
            "23/23 [==============================] - 183s 8s/step - loss: 0.5574 - accuracy: 0.9114 - val_loss: 5.3753e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/25\n",
            "23/23 [==============================] - 4s 163ms/step - loss: 0.0211 - accuracy: 0.9986 - val_loss: 0.0079 - val_accuracy: 0.9969\n",
            "Epoch 3/25\n",
            "23/23 [==============================] - 4s 165ms/step - loss: 0.0596 - accuracy: 0.9891 - val_loss: 0.0258 - val_accuracy: 0.9906\n",
            "Epoch 4/25\n",
            "23/23 [==============================] - 4s 174ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.5167e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "23/23 [==============================] - 4s 175ms/step - loss: 5.7140e-06 - accuracy: 1.0000 - val_loss: 4.3378e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 4.2868e-07 - accuracy: 1.0000 - val_loss: 1.8423e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 2.2577e-07 - accuracy: 1.0000 - val_loss: 1.3082e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.6511e-07 - accuracy: 1.0000 - val_loss: 7.9579e-08 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.3225e-07 - accuracy: 1.0000 - val_loss: 3.9694e-08 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "23/23 [==============================] - 4s 167ms/step - loss: 1.0386e-07 - accuracy: 1.0000 - val_loss: 6.7181e-08 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "23/23 [==============================] - 4s 165ms/step - loss: 8.1299e-08 - accuracy: 1.0000 - val_loss: 5.4603e-08 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "23/23 [==============================] - 4s 166ms/step - loss: 6.6324e-08 - accuracy: 1.0000 - val_loss: 4.7025e-08 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "23/23 [==============================] - 4s 171ms/step - loss: 5.4914e-08 - accuracy: 1.0000 - val_loss: 3.8016e-08 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "23/23 [==============================] - 4s 170ms/step - loss: 2.2200e-08 - accuracy: 1.0000 - val_loss: 3.6974e-08 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "23/23 [==============================] - 4s 170ms/step - loss: 4.1362e-08 - accuracy: 1.0000 - val_loss: 3.5299e-08 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "23/23 [==============================] - 4s 171ms/step - loss: 3.7973e-08 - accuracy: 1.0000 - val_loss: 2.7863e-08 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "23/23 [==============================] - 4s 169ms/step - loss: 3.1240e-08 - accuracy: 1.0000 - val_loss: 2.4942e-08 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "23/23 [==============================] - 4s 174ms/step - loss: 2.7553e-08 - accuracy: 1.0000 - val_loss: 2.1571e-08 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "23/23 [==============================] - 4s 174ms/step - loss: 2.4311e-08 - accuracy: 1.0000 - val_loss: 1.8995e-08 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "23/23 [==============================] - 4s 173ms/step - loss: 2.1683e-08 - accuracy: 1.0000 - val_loss: 1.6884e-08 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "23/23 [==============================] - 4s 173ms/step - loss: 1.9240e-08 - accuracy: 1.0000 - val_loss: 1.5611e-08 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "23/23 [==============================] - 4s 175ms/step - loss: 1.7278e-08 - accuracy: 1.0000 - val_loss: 1.6038e-09 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "23/23 [==============================] - 4s 168ms/step - loss: 6.8824e-09 - accuracy: 1.0000 - val_loss: 1.3620e-08 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "23/23 [==============================] - 4s 165ms/step - loss: 1.5042e-08 - accuracy: 1.0000 - val_loss: 1.2418e-08 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "23/23 [==============================] - 4s 165ms/step - loss: 1.3629e-08 - accuracy: 1.0000 - val_loss: 4.7391e-09 - val_accuracy: 1.0000\n",
            "Epoch 1/25\n",
            "23/23 [==============================] - 187s 8s/step - loss: 0.0989 - accuracy: 0.9768 - val_loss: 6.7223e-15 - val_accuracy: 1.0000\n",
            "Epoch 2/25\n",
            "23/23 [==============================] - 6s 264ms/step - loss: 6.7178e-13 - accuracy: 1.0000 - val_loss: 1.4765e-12 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "23/23 [==============================] - 5s 232ms/step - loss: 2.1190e-10 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9969\n",
            "Epoch 4/25\n",
            "23/23 [==============================] - 5s 214ms/step - loss: 1.1212e-09 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
            "Epoch 5/25\n",
            "23/23 [==============================] - 5s 214ms/step - loss: 1.1857e-09 - accuracy: 1.0000 - val_loss: 7.4832e-12 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "23/23 [==============================] - 5s 215ms/step - loss: 1.1826e-09 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9969\n",
            "Epoch 7/25\n",
            "23/23 [==============================] - 5s 226ms/step - loss: 1.1755e-09 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9969\n",
            "Epoch 8/25\n",
            "23/23 [==============================] - ETA: 0s - loss: 1.1674e-09 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 1.\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.1674e-09 - accuracy: 1.0000 - val_loss: 7.3542e-12 - val_accuracy: 1.0000\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/25\n",
            "47/47 [==============================] - 175s 4s/step - loss: 0.1262 - accuracy: 0.9627 - val_loss: 2.6522e-08 - val_accuracy: 1.0000\n",
            "Epoch 2/25\n",
            "47/47 [==============================] - 18s 394ms/step - loss: 2.3312e-07 - accuracy: 1.0000 - val_loss: 5.1712e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 1.3573e-07 - accuracy: 1.0000 - val_loss: 1.5764e-14 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "47/47 [==============================] - 7s 157ms/step - loss: 6.8341e-08 - accuracy: 1.0000 - val_loss: 2.7384e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "47/47 [==============================] - 8s 171ms/step - loss: 3.7015e-08 - accuracy: 1.0000 - val_loss: 1.9431e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "47/47 [==============================] - 6s 122ms/step - loss: 2.1492e-08 - accuracy: 1.0000 - val_loss: 1.5282e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "47/47 [==============================] - 5s 105ms/step - loss: 1.3740e-08 - accuracy: 1.0000 - val_loss: 1.5918e-10 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "47/47 [==============================] - 4s 92ms/step - loss: 9.5801e-09 - accuracy: 1.0000 - val_loss: 1.3139e-10 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "47/47 [==============================] - 4s 89ms/step - loss: 7.1890e-09 - accuracy: 1.0000 - val_loss: 1.2869e-10 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "47/47 [==============================] - ETA: 0s - loss: 5.5515e-09 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 3.\n",
            "47/47 [==============================] - 4s 92ms/step - loss: 5.5515e-09 - accuracy: 1.0000 - val_loss: 8.8189e-06 - val_accuracy: 1.0000\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model1.save ( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model1/' )\n",
        "# model21.save( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model21/')\n",
        "# model22.save( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model22/')\n",
        "# model23.save( '/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model23/')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "model1 =tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model1/' )\n",
        "model21=tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model21/')\n",
        "model22=tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model22/')\n",
        "model23=tf.keras.models.load_model('/content/drive/My Drive/db/6C/Bipartite_Adam_pln_pp/model23/')\n"
      ],
      "metadata": {
        "id": "Kid9nhG98y-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss/accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "_3suQyk5DIUl",
        "outputId": "6415825d-28db-487c-c7bd-537cee0454c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHwCAYAAAC2blbYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwV1Z3H/c+PBmxAQAQUZBFMUNlsQECUoEbEoCYYdZQ40QnE5XFLYhYMLuOWZTQhajIRFRONGuMyqBOfCYriboILEFTcNxQQpEFE9q3P80df+2kRmob07dvV/Xm/Xv3yVtW5p363QL59qurWiZQSkiQpexoVugBJkrRjDHFJkjLKEJckKaMMcUmSMsoQlyQpowxxSZIyyhCXJCmjDHGpDoiIuRFxeC3ta2pEHFEb+5KUX4a41IBERAtgIPBkHailcaFrkLLOEJfqqIjYKSKujYgPcz/XRsROuW3tIuL/IuKTiPg4Ip6OiEa5bT+NiAURsSIi3oiI4ZW6HQ78PaW0LiIGR8T0XB8LI+L3EdG00v57R8Qjuf4/iogLc+uLIuLCiHgnt4+ZEdElIrpFRKoczhHxRESclns9JiL+HhHXRMRS4LKI+FJEPBYRSyNiSUTcERG7VHp/l4i4LyJKc21+HxFNczX1rdRut4hYHRHt8/THIdVJhrhUd10EDAH6ASXAYODi3LYfA/OB9sDuwIVAioh9gHOBQSmllsDXgLmV+jwK+Fvu9Sbgh0A74EDKA/5sgIhoCUwDHgL2AL4MPJp734+Ak3J9tQK+C6yu5mc6AHg3V/MvgAD+K7ePnkAX4LJcDUXA/wHvA92ATsBdKaX1wF3AyZX6PQl4NKVUWs06pHrBEJfqrm8DV6SUFufC6XLglNy2DUBHYM+U0oaU0tOpfCKETcBOQK+IaJJSmptSeqdSn0cBUwBSSjNTSs+mlDamlOYCNwKH5Np9HViUUvpNSmltSmlFSum53LbTgItTSm+kci+mlJZW8zN9mFL679w+16SU3k4pPZJSWpf7jFdXqmEw5eE+LqW0KlfHM7lttwInRUTklk8Bbq9mDVK9YYhLddcelI9CP/N+bh3Ar4G3gYcj4t2IGA+QUnobOI/y0eziiLgrIvYAyJ1+Xp5Smpdb3jt3Sn5RRHwK/JLyUTmUj4grh39lVW3blnmVFyJi91yNC3I1/HmzGt5PKW3cvJPcLxSrgUMjYl/KzxQ8sIM1SZlliEt114fAnpWWu+bWkRsZ/ziltBcwCvjRZ9e+U0p/SSl9JffeBFyVe3/FKDzneuB1oEdKqRXlp+Q/G9nOA/baSl3zgC9tYf2q3H+bV1rXYbM2m0+b+Mvcur65Gk7erIauVdwAd2uu/SnA5JTS2q20k+otQ1yqO5pERPFnP8CdwMUR0T4i2gGXUD5SJSK+HhFfzp1OXk75afSyiNgnIg7L3QC3FlgDlOX6r3w9HKAl8CmwMjeaPavStv8DOkbEebkb7FpGxAG5bX8AfhYRPaLcfhHRNnc6fAFwcu7mt++y5bCvrCWwElgeEZ2AcZW2PQ8sBK6MiBa54zK00vY/A8dSHuS3bWM/Ur1kiEt1xxTKQ/ezn2JgBvAS8DIwC/h5rm0Pym88WwlMByamlB6n/Hr4lcASYBGwG3BB7o7vXsA/Ku3vJ8C/AyuAm4C7P9uQUloBjAC+kevnLeCruc1XA/cAD1P+S8AfgWa5badTHsRLgd6b7W9LLgcGUP6LyN+A+yrVsCm3/y8DH1B+I9/oStvn5Y5JAp7exn6keinK74WRVJ9FxInAv6WUTix0LTUpIm6m/Ga5i7fZWKqHfNiC1DB8AlxT6CJqUkR0A44D+he2EqlwPJ0uNQAppYdTStMLXUdNiYifAXOAX6eU3it0PVKheDpdkqSMciQuSVJGGeKSJGVU5m5sa9euXerWrVuhy5AkqVbMnDlzSUppi5P7ZC7Eu3XrxowZMwpdhiRJtSIi3t/aNk+nS5KUUYa4JEkZZYhLkpRRhrgkSRlliEuSlFGGuCRJGWWIS5KUUYa4JEkZZYhLkpRRhrgkSRlliEuSlFGGuCRJGWWIS5KUUYa4JEkZlbcQj4ibI2JxRMzZyvaIiN9FxNsR8VJEDMhXLZIk1Uf5HIn/CRhZxfYjgR65nzOA6/NYiyRJ9U7jfHWcUnoqIrpV0eQY4LaUUgKejYhdIqJjSmlhvmqqL1at28jGslToMiRJWxABrYqb1Mq+8hbi1dAJmFdpeX5uXe2F+IPjYdHLtba7f8XaDZtYumo9H69az6r1GwtdjiRpK95u1J2TL7uzVvZVyBCvtog4g/JT7nTt2rXA1dSeNRs2sXTVOj5etZ7V6zcB0KJpYzrv0oyiRlHg6iRJW9K6dZta21chQ3wB0KXScufcui9IKU0CJgEMHDiw5s4jH3lljXVVE1JKvPHRCqa8vIiH5izkzY9WArD/nm04sk8HRvbpQOc2zQtcpSSpKh1rcV+FDPEHgHMj4i7gAGB5Q7wenlLilQ8/5cE5C3nw5UW8u2QVETCo265c9o1ejOzTkQ6tiwtdpiSpDspbiEfEncChQLuImA9cCjQBSCndAEwBjgLeBlYDY/NVS12TUuLF+ct58OWFTJmzkHkfr6GoUTBkr1357le6c0Tv3dmtpcEtSapaPu9OP2kb2xNwTr72X9eUlSVmfbCMB+cs4qE5i1jwyRoaNwqGfrkd5371y4zo1YFdWzQtdJmSpAzJxI1tWbWpLPHC3I958OWFPPTKIj76dB1NixoxrEc7fjhib0b03J3WzWvnawiSpPrHEK9hGzeV8dx7HzPl5YVMfWURS1auZ6fGjTh0n/Yc1bcjh+27Gy1r6fuDkqT6zRCvAes3lvGPd5bw4MuLePjVRSxbvYFmTYo4bN/dOLJvB766z2602MlDLUmqWSbLDlq7YRPPvLWEB+cs4pFXF/Hp2o3svFNjhvfcjSP7dOSQvdvTrGlRocuUJNVjhvh2WLthE0+8UcqDcxby6GuLWbluI62KGzOiVweO7NOBr/RoR3ETg1uSVDsM8W1YtW4jj7+xmAdfXsTjbyxm9fpNtGnehKP7duTIvh046EvtaNrYGV0lSbXPEN+CFWs38Njri5ny8kKeeKOUdRvLaLdzU47t34mj+nbkgO670rjI4JYkFZYhnrN89QYeee0jHnx5IU+/tYT1m8rYvdVOfGtQF47s25FB3Xb1eeWSpDqlQYf4slXrefjVRUx5eRF/f3sJG8sSe7Qu5pQD9+Sovh3o36UNjQxuSVId1aBD/P9eXsh//u8cuu7anFOHdefIPh0p6dyaCINbklT3NegQ/8Z+HenfZRd679HK4JYkZU6DDvFdmjdll+Y+r1ySlE3eYi1JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRlVF5DPCJGRsQbEfF2RIzfwvauEfF4RPwzIl6KiKPyWY8kSfVJ3kI8IoqA64AjgV7ASRHRa7NmFwP3pJT6A98CJuarHkmS6pt8jsQHA2+nlN5NKa0H7gKO2axNAlrlXrcGPsxjPZIk1SuN89h3J2BepeX5wAGbtbkMeDgivge0AA7PYz2SJNUrhb6x7STgTymlzsBRwO0R8YWaIuKMiJgRETNKS0trvUhJkuqifIb4AqBLpeXOuXWVnQrcA5BSmg4UA+027yilNCmlNDClNLB9+/Z5KleSpGzJZ4i/APSIiO4R0ZTyG9ce2KzNB8BwgIjoSXmIO9SWJKka8hbiKaWNwLnAVOA1yu9CfyUiroiIUblmPwZOj4gXgTuBMSmllK+aJEmqT/J5YxsppSnAlM3WXVLp9avA0HzWIElSfVXoG9skSdIOMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyihDXJKkjDLEJUnKKENckqSMMsQlScooQ1ySpIwyxCVJyqi8hnhEjIyINyLi7YgYv5U2J0bEqxHxSkT8JZ/1SJJUnzTOV8cRUQRcB4wA5gMvRMQDKaVXK7XpAVwADE0pLYuI3fJVjyRJ9U0+R+KDgbdTSu+mlNYDdwHHbNbmdOC6lNIygJTS4jzWI0lSvZLPEO8EzKu0PD+3rrK9gb0j4u8R8WxEjMxjPZIk1St5O52+HfvvARwKdAaeioi+KaVPKjeKiDOAMwC6du1a2zVKklQn5XMkvgDoUmm5c25dZfOBB1JKG1JK7wFvUh7qn5NSmpRSGphSGti+ffu8FSxJUpbkM8RfAHpERPeIaAp8C3hgszb/S/konIhoR/np9XfzWJMkSfVG3kI8pbQROBeYCrwG3JNSeiUiroiIUblmU4GlEfEq8DgwLqW0NF81SZJUn0RKqdA1bJeBAwemGTNmFLoMSZJqRUTMTCkN3NI2n9gmSVJGGeKSJGWUIS5JUkYV+nvikqRt2LBhA/Pnz2ft2rWFLkV5VFxcTOfOnWnSpEm132OIS1IdN3/+fFq2bEm3bt2IiEKXozxIKbF06VLmz59P9+7dq/0+T6dLUh23du1a2rZta4DXYxFB27Ztt/tsiyEuSRlggNd/O/JnbIhLkqr0ySefMHHixB1671FHHcUnn3xSZZtLLrmEadOm7VD/DZ0hLkmqUlUhvnHjxirfO2XKFHbZZZcq21xxxRUcfvjhO1xfIWzrc9cWQ1ySVKXx48fzzjvv0K9fP8aNG8cTTzzBsGHDGDVqFL169QLgm9/8Jvvvvz+9e/dm0qRJFe/t1q0bS5YsYe7cufTs2ZPTTz+d3r17c8QRR7BmzRoAxowZw+TJkyvaX3rppQwYMIC+ffvy+uuvA1BaWsqIESPo3bs3p512GnvuuSdLliz5Qq1nnXUWAwcOpHfv3lx66aUV61944QUOOuggSkpKGDx4MCtWrGDTpk385Cc/oU+fPuy3337893//9+dqBpgxYwaHHnooAJdddhmnnHIKQ4cO5ZRTTmHu3LkMGzaMAQMGMGDAAP7xj39U7O+qq66ib9++lJSUVBy/AQMGVGx/6623Pre8o7w7XZIy5PL/9xVe/fDTGu2z1x6tuPQbvbe6/corr2TOnDnMnj0bgCeeeIJZs2YxZ86cijupb775ZnbddVfWrFnDoEGDOP7442nbtu3n+nnrrbe48847uemmmzjxxBO59957Ofnkk7+wv3bt2jFr1iwmTpzIhAkT+MMf/sDll1/OYYcdxgUXXMBDDz3EH//4xy3W+otf/IJdd92VTZs2MXz4cF566SX23XdfRo8ezd13382gQYP49NNPadasGZMmTWLu3LnMnj2bxo0b8/HHH2/zWL366qs888wzNGvWjNWrV/PII49QXFzMW2+9xUknncSMGTN48MEH+etf/8pzzz1H8+bN+fjjj9l1111p3bo1s2fPpl+/ftxyyy2MHTt2m/vbFkNckrTdBg8e/LmvQv3ud7/j/vvvB2DevHm89dZbXwjx7t27069fPwD2339/5s6du8W+jzvuuIo29913HwDPPPNMRf8jR46kTZs2W3zvPffcw6RJk9i4cSMLFy7k1VdfJSLo2LEjgwYNAqBVq1YATJs2jTPPPJPGjcujcNddd93m5x41ahTNmjUDyr+/f+655zJ79myKiop48803K/odO3YszZs3/1y/p512GrfccgtXX301d999N88///w297cthrgkZUhVI+ba1KJFi4rXTzzxBNOmTWP69Ok0b96cQw89dItfldppp50qXhcVFVWcTt9au6Kiou269vzee+8xYcIEXnjhBdq0acOYMWN26AE5jRs3pqysDOAL76/8ua+55hp23313XnzxRcrKyiguLq6y3+OPP77ijML+++//hV9ydoTXxCVJVWrZsiUrVqzY6vbly5fTpk0bmjdvzuuvv86zzz5b4zUMHTqUe+65B4CHH36YZcuWfaHNp59+SosWLWjdujUfffQRDz74IAD77LMPCxcu5IUXXgBgxYoVbNy4kREjRnDjjTdW/KLw2en0bt26MXPmTADuvfferda0fPlyOnbsSKNGjbj99tvZtGkTACNGjOCWW25h9erVn+u3uLiYr33ta5x11lk1ciodDHFJ0ja0bduWoUOH0qdPH8aNG/eF7SNHjmTjxo307NmT8ePHM2TIkBqv4dJLL+Xhhx+mT58+/M///A8dOnSgZcuWn2tTUlJC//792Xffffn3f/93hg4dCkDTpk25++67+d73vkdJSQkjRoxg7dq1nHbaaXTt2pX99tuPkpIS/vKXv1Ts6wc/+AEDBw6kqKhoqzWdffbZ3HrrrZSUlPD6669XjNJHjhzJqFGjGDhwIP369WPChAkV7/n2t79No0aNOOKII2rkuDifuCTVca+99ho9e/YsdBkFtW7dOoqKimjcuDHTp0/nrLPOqrjRLksmTJjA8uXL+dnPfrbF7Vv6s65qPnGviUuS6rwPPviAE088kbKyMpo2bcpNN91U6JK227HHHss777zDY489VmN9GuKSpDqvR48e/POf/yx0Gf+Sz+6ur0leE5ckKaMMcUmSMsoQlyQpowxxSZIyyhCXJNW4nXfeudAlNAiGuCSp3qkrU4XmmyEuSarS+PHjue666yqWL7vsMiZMmMDKlSsZPnx4xbShf/3rX7fZ19amLH3ooYcYMGAAJSUlDB8+HICVK1cyduxY+vbty3777VfxCNTKo/zJkyczZswYoHxK0zPPPJMDDjiA888/n+eff54DDzyQ/v37c9BBB/HGG28AbHEK0scee4xvfvObFf0+8sgjHHvssTt+0GqJ3xOXpCx5cDwserlm++zQF468cqubR48ezXnnncc555wDlM8UNnXqVIqLi7n//vtp1aoVS5YsYciQIYwaNYqI2GpfW5qytKysjNNPP52nnnqK7t27Vzxr/Gc/+xmtW7fm5ZfLP++Wnpe+ufnz5/OPf/yDoqIiPv30U55++mkaN27MtGnTuPDCC7n33nu3OAVpmzZtOPvssyktLaV9+/bccsstfPe7392eo1gQhrgkqUr9+/dn8eLFfPjhh5SWltKmTRu6dOnChg0buPDCC3nqqado1KgRCxYs4KOPPqJDhw5b7WtLU5aWlpZy8MEHV0xt+tnUndOmTeOuu+6qeO/Wph+t7IQTTqh43vny5cv5zne+w1tvvUVEsGHDhop+tzQF6SmnnMKf//xnxo4dy/Tp07ntttu291DVumqFeET8ALgFWAH8AegPjE8pPZzH2iRJm6tixJxPJ5xwApMnT2bRokWMHj0agDvuuIPS0lJmzpxJkyZN6NatW5VTf1Z3ytJtqTzSr2qq0P/8z//kq1/9Kvfffz9z587l0EMPrbLfsWPH8o1vfIPi4mJOOOGEipCvy6p7Tfy7KaVPgSOANsApQGH+JkmSat3o0aO56667mDx5MieccAJQPtLdbbfdaNKkCY8//jjvv/9+lX1sbcrSIUOG8NRTT/Hee+8B///UnSNGjPjctfjPTqfvvvvuvPbaa5SVlVX5KNPly5fTqVMnAP70pz9VrN/aFKR77LEHe+yxBz//+c9rbKrQfKtuiH/2a89RwO0ppVcqrZMk1XO9e/dmxYoVdOrUiY4dOwLl02rOmDGDvn37ctttt7HvvvtW2cfWpixt3749kyZN4rjjjqOkpKRipH/xxRezbNky+vTpQ0lJCY8//jgAV155JV//+tc56KCDKmrZkvPPP58LLriA/v37f+5u9a1NQfrZZ+rSpUtmZo2r1lSkEXEL0AnoDpQARcATKaX981veFzkVqaSGxqlIa8+5555L//79OfXUUwuy/3xNRXoq0A94N6W0OiJ2BbJxrkGSpGrYf//9adGiBb/5zW8KXUq1VTfEDwRmp5RWRcTJwADgt/krS5Kk2jVz5sxCl7DdqntN/HpgdUSUAD8G3gHq/r33kiTVY9UN8Y2p/OL5McDvU0rXAS3zV5YkSdqW6p5OXxERF1D+1bJhEdEIaJK/siRJ0rZUdyQ+GlhH+ffFFwGdgV/nrSpJkrRN1QrxXHDfAbSOiK8Da1NKXhOXpAbgk08+YeLEiTv03qOOOopPPvmkyjaXXHIJ06ZN26H+N9etWzeWLFlSI31lQbVCPCJOBJ4HTgBOBJ6LiH/LZ2GSpLqhqhDf1pSfU6ZMYZdddqmyzRVXXMHhhx++w/U1ZNU9nX4RMCil9J2U0n8Ag4H/zF9ZkqS6Yvz48bzzzjv069ePcePG8cQTTzBs2DBGjRpFr169gK1PMfrZyHju3Ln07NmT008/nd69e3PEEUewZs0aoHwK0cmTJ1e0v/TSSyumN3399dcBKC0tZcSIEfTu3ZvTTjuNPffcc5sj7quvvpo+ffrQp08frr32WgBWrVrF0UcfTUlJCX369OHuu++u+Iy9evViv/324yc/+UnNHsA8qu6NbY1SSosrLS/FucglqdZd9fxVvP7x6zXa57677stPB/90q9uvvPJK5syZw+zZs4HyiUxmzZrFnDlzKmYe29IUo23btv1cP2+99RZ33nknN910EyeeeCL33nsvJ5988hf2165dO2bNmsXEiROZMGECf/jDH7j88ss57LDDuOCCC3jooYf44x//WOVnmjlzJrfccgvPPfccKSUOOOAADjnkEN5991322GMP/va3vwHlz1dfunQp999/P6+//joRsc3T/3VJdYP4oYiYGhFjImIM8DdgSv7KkiTVZYMHD64IcCifYrSkpIQhQ4ZUTDG6ue7du9OvXz+g/Oloc+fO3WLfxx133BfaPPPMM3zrW98Cyp/Bvq1pSZ955hmOPfZYWrRowc4778xxxx3H008/Td++fXnkkUf46U9/ytNPP03r1q1p3bo1xcXFnHrqqdx33300b958ew9HwVRrJJ5SGhcRxwNDc6smpZS2PnWMJCkvqhox16bKU35Wd4rRnXbaqeJ1UVFRxen0rbUrKira5jX37bX33nsza9YspkyZwsUXX8zw4cO55JJLeP7553n00UeZPHkyv//973nsscdqdL/5Uu1T4imle1NKP8r9GOCS1EC0bNmSFStWbHX71qYYrUlDhw7lnnvuAeDhhx+umJZ0a4YNG8b//u//snr1alatWsX999/PsGHD+PDDD2nevDknn3wy48aNY9asWaxcuZLly5dz1FFHcc011/Diiy/WeP35UuVIPCJWAFua5iyAlFJqlZeqJEl1Rtu2bRk6dCh9+vThyCOP5Oijj/7c9pEjR3LDDTfQs2dP9tlnn4opRmvSpZdeykknncTtt9/OgQceSIcOHWjZcusPDh0wYABjxoxh8ODBQPn0o/3792fq1KmMGzeORo0a0aRJE66//npWrFjBMcccw9q1a0kpcfXVV9d4/flSralI6xKnIpXU0DgVKaxbt46ioiIaN27M9OnTOeussyputKtP8jUVqSRJBfPBBx9w4oknUlZWRtOmTbnpppsKXVKdYIhLkuq8Hj168M9//rPQZdQ5ftdbkqSMMsQlScooQ1ySpIwyxCVJyihDXJJU43beeeftWq8dY4hLkpRRhrgkqUrjx4/nuuuuq1i+7LLLmDBhAitXrmT48OEV04b+9a9/rXafKSXGjRtHnz596Nu3b8WUoAsXLuTggw+mX79+9OnTh6effppNmzYxZsyYirbXXHNNjX/GrPJ74pKUIYt++UvWvVazU5Hu1HNfOlx44Va3jx49mvPOO49zzjkHgHvuuYepU6dSXFzM/fffT6tWrViyZAlDhgxh1KhRRMQ293nfffcxe/ZsXnzxRZYsWcKgQYM4+OCD+ctf/sLXvvY1LrroIjZt2sTq1auZPXs2CxYsYM6cOQCZmio03wxxSVKV+vfvz+LFi/nwww8pLS2lTZs2dOnShQ0bNnDhhRfy1FNP0ahRIxYsWMBHH31Ehw4dttnnM888w0knnURRURG77747hxxyCC+88AKDBg3iu9/9Lhs2bOCb3/wm/fr1Y6+99uLdd9/le9/7HkcffTRHHHFELXzqbDDEJSlDqhox59MJJ5zA5MmTWbRoEaNHjwbgjjvuoLS0lJkzZ9KkSRO6deu2xSlIt8fBBx/MU089xd/+9jfGjBnDj370I/7jP/6DF198kalTp3LDDTdwzz33cPPNN9fEx8o8r4lLkrZp9OjR3HXXXUyePJkTTjgBKJ+CdLfddqNJkyY8/vjjvP/++9Xub9iwYdx9991s2rSJ0tJSnnrqKQYPHsz777/P7rvvzumnn85pp53GrFmzWLJkCWVlZRx//PH8/Oc/Z9asWfn6mJnjSFyStE29e/dmxYoVdOrUiY4dOwLw7W9/m2984xv07duXgQMHsu+++1a7v2OPPZbp06dTUlJCRPCrX/2KDh06cOutt/LrX/+aJk2asPPOO4qZQjcAABFmSURBVHPbbbexYMECxo4dS1lZGQD/9V//lZfPmEVORSpJdZxTkTYc2zsVqafTJUnKKENckqSMMsQlScooQ1ySMiBr9y9p++3In7EhLkl1XHFxMUuXLjXI67GUEkuXLqW4uHi73udXzCSpjuvcuTPz58+ntLS00KUoj4qLi+ncufN2vccQl6Q6rkmTJnTv3r3QZagO8nS6JEkZZYhLkpRReQ3xiBgZEW9ExNsRMb6KdsdHRIqILT6RRpIkfVHeQjwiioDrgCOBXsBJEdFrC+1aAj8AnstXLZIk1Uf5HIkPBt5OKb2bUloP3AUcs4V2PwOuAv61+eskSWpg8hninYB5lZbn59ZViIgBQJeU0t/yWIckSfVSwW5si4hGwNXAj6vR9oyImBERM/yepCRJ5fIZ4guALpWWO+fWfaYl0Ad4IiLmAkOAB7Z0c1tKaVJKaWBKaWD79u3zWLIkSdmRzxB/AegREd0joinwLeCBzzamlJanlNqllLqllLoBzwKjUkpOFi5JUjXkLcRTShuBc4GpwGvAPSmlVyLiiogYla/9SpLUUOT1sasppSnAlM3WXbKVtofmsxZJkuobn9gmSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGWUIS5JUkYZ4pIkZVReQzwiRkbEGxHxdkSM38L2H0XEqxHxUkQ8GhF75rMeSZLqk7yFeEQUAdcBRwK9gJMiotdmzf4JDEwp7QdMBn6Vr3okSapv8jkSHwy8nVJ6N6W0HrgLOKZyg5TS4yml1bnFZ4HOeaxHkqR6JZ8h3gmYV2l5fm7d1pwKPJjHeiRJqlcaF7oAgIg4GRgIHLKV7WcAZwB07dq1FiuTJKnuyudIfAHQpdJy59y6z4mIw4GLgFEppXVb6iilNCmlNDClNLB9+/Z5KVaSpKzJZ4i/APSIiO4R0RT4FvBA5QYR0R+4kfIAX5zHWiRJqnfyFuIppY3AucBU4DXgnpTSKxFxRUSMyjX7NbAz8D8RMTsiHthKd5IkaTN5vSaeUpoCTNls3SWVXh+ez/1LklSf+cQ2SZIyyhCXJCmjDHFJkjLKEJckKaMMcUmSMsoQlyQpowxxSZIyyhCXJCmjDHFJkjLKEJckKaMMcUmSMsoQlyQpowxxSZIyyhCXJCmjDHFJkjLKEJckKaMMcUmSMsoQlyQpowxxSZIyyhCXJCmjDHFJkjLKEJckKaMMcUmSMqpBh/iby97kR0/8iDUb1xS6FEmStluDDvF5n85j2vvTGPfkODaWbSx0OZIkbZcGHeLD9xzORQdcxJPzn+SK6VeQUip0SZIkVVvjQhdQaKP3HU3pmlJufOlG2jVrx/cHfL/QJUmSVC0NPsQBzul3DkvWLOGml2+ibbO2fLvntwtdkiRJ22SIAxHBxUMu5uO1H3PV81fRtllbRnYbWeiyJEmqUoO+Jl5Z40aN+dXBv6L/bv258OkLeW7hc4UuSZKkKhnilRQ3LuZ3h/2OPVvtyQ8e/wGvLX2t0CVJkrRVhvhmWu/UmusPv56WTVty1rSzmLdiXqFLkiRpiwzxLejQogM3Hn4jG9NGznzkTJauWVrokiRJ+gJDfCv22mUvfn/Y71m8ejFnP3o2qzasKnRJkiR9jiFehX679WPCIRN44+M3OO/x89iwaUOhS5IkqYIhvg2HdDmESw+8lGcXPstFf7+IslRW6JIkSQL8nni1HNvjWJauXcpvZ/2Wds3aMW7gOCKi0GVJkho4Q7yaTu1zKkvWLOH2V2+nfbP2jO0zttAlSZIaOEO8miKC8wedz9I1S7l65tW0bdaWUV8aVeiyJEkNmCG+HRpFI37xlV+wbN0yLvn7JbTZqQ3DOg8rdFmSpAbKG9u2U9Oiplx76LXs3WZvfvzkj3mp9KVClyRJaqAM8R2wc9OdmXj4RNoWt+WcR8/hveXvFbokSVIDZIjvoHbN2nHjiBtpFI0485EzWbx6caFLkiQ1MIb4v6Brq65MPHwin6z7hDOnncmn6z8tdEmSpAbEEP8X9W7bm2u+eg3vLX+P7z/2fdZtWlfokiRJDYQhXgMO2uMgfvmVXzLzo5mMf2o8m8o2FbokSVIDYIjXkCO7H8n5g85n2gfT+OVzvySlVOiSJEn1nN8Tr0Gn9DqFJWuWcPOcm2nXvB1nlZxV6JIkSfWYIV7DzhtwHkvWLGHi7PKvoJ24z4mFLkmSVE8Z4jUsIrjsoMtYtnYZv3juF7Rt1pbhXYcXuixJUj3kNfE8aNKoCRMOmUCftn04/8nzmbFoRqFLkiTVQ4Z4njRv0pzfD/89e+y8B99/7Pu8uezNQpckSapnDPE8alPchhtH3Eizxs0465Gz+HDlh4UuSZJUjxjiebbHzntw/YjrWbNxDf/PI/8Py9YuK3RJkqR6whCvBXu32ZvfHfY7Plz5Iec+ei6rN6wudEmSpHrAEK8lAzsM5FcH/4o5S+fwkyd/woayDYUuSZKUcYZ4LRq+53AuOuAinl7wNJf94zKf6iZJ+pf4PfFaduI+J7J0zVImvjiRds3a8cP9f1jokiRJGWWIF8CZJWdSuqaUm+fcTPtm7Tm518mFLkmSlEGGeAFEBBcdcBEfr/2Yq164irbN2nJk9yMLXZYkKWO8Jl4gRY2KuOrgq9h/9/258JkLmf7h9EKXJEnKGEO8gHYq2onfHfY7urfuznmPn8crS18pdEmSpAwxxAusVdNW3HD4DbTeqTVnTzubeZ/OK3RJkqSMMMTrgN2a78YNI26gLJVxxiNnsGTNkkKXJEnKAEO8jtir9V5cN/w6lq5dytnTzmbl+pWFLkmSVMcZ4nXIfu334zeH/IY3l73JeU+cx/pN6wtdkiSpDjPE65hhnYdxxdAreG7hc1z0zEWUpbJClyRJqqP8nngdNOpLo1iyZgnXzLyGts3a8tNBPyUiCl2WJKmOMcTrqLG9x1K6upQ/v/Zn2jVrx2l9Tyt0SZKkOsYQr6MignGDxrF07VJ+O+u3tC1uy7E9ji10WZKkOiSv18QjYmREvBERb0fE+C1s3yki7s5tfy4iuuWznqxpFI34xdBfMKTjEC6ffjlPznuy0CVJkuqQvIV4RBQB1wFHAr2AkyKi12bNTgWWpZS+DFwDXJWverKqSVETrv3qteyz6z785MmfMHvx7EKXJEmqI/I5Eh8MvJ1SejeltB64CzhmszbHALfmXk8Ghod3cH1BiyYtmDh8Iu2bt+fcx87l3U/eLXRJkqQ6IJ/XxDsBlZ8hOh84YGttUkobI2I50BaolUeWrXz6GT7+05+qbpRSNXqqThtI1emriibXbmzNK0sX8OKtx/J2k+Y1U1U1fmVK/l4lfUHyf4taEdX757VOKWvWlKPufKJW9pWJG9si4gzgDICuXbvWWL9pwwbKVlbjyWjVCbHqBt2/0FdTiti31ZeYv2IBZRs2VN1FqlY+b1s1+qnWflKq/jHaARn8/1w5mczCav1yrxqTsYFEtQZsNSSfIb4A6FJpuXNu3ZbazI+IxkBrYOnmHaWUJgGTAAYOHFhjR6flYV+l5WFfranuak3PQhcgSaoT8nlN/AWgR0R0j4imwLeABzZr8wDwndzrfwMeS7X5K4wkSRmWt5F47hr3ucBUoAi4OaX0SkRcAcxIKT0A/BG4PSLeBj6mPOglSVI15PWaeEppCjBls3WXVHq9FjghnzVIklRfOQGKJEkZZYhLkpRRhrgkSRlliEuSlFGGuCRJGWWIS5KUUYa4JEkZZYhLkpRRhrgkSRlliEuSlFGGuCRJGWWIS5KUUYa4JEkZZYhLkpRRhrgkSRkVKaVC17BdIqIUeL8Gu2wHLKnB/rR1Huva4XGuHR7n2uFxhj1TSu23tCFzIV7TImJGSmlgoetoCDzWtcPjXDs8zrXD41w1T6dLkpRRhrgkSRlliMOkQhfQgHisa4fHuXZ4nGuHx7kKDf6auCRJWeVIXJKkjGrQIR4RIyPijYh4OyLGF7qe+igiukTE4xHxakS8EhE/KHRN9VlEFEXEPyPi/wpdS30VEbtExOSIeD0iXouIAwtdU30VET/M/bsxJyLujIjiQtdU1zTYEI+IIuA64EigF3BSRPQqbFX10kbgxymlXsAQ4ByPc179AHit0EXUc78FHkop7QuU4PHOi4joBHwfGJhS6gMUAd8qbFV1T4MNcWAw8HZK6d2U0nrgLuCYAtdU76SUFqaUZuVer6D8H7xOha2qfoqIzsDRwB8KXUt9FRGtgYOBPwKklNanlD4pbFX1WmOgWUQ0BpoDHxa4njqnIYd4J2BepeX5GC55FRHdgP7Ac4WtpN66FjgfKCt0IfVYd6AUuCV32eIPEdGi0EXVRymlBcAE4ANgIbA8pfRwYauqexpyiKsWRcTOwL3AeSmlTwtdT30TEV8HFqeUZha6lnquMTAAuD6l1B9YBXg/TR5ERBvKz452B/YAWkTEyYWtqu5pyCG+AOhSablzbp1qWEQ0oTzA70gp3VfoeuqpocCoiJhL+aWhwyLiz4UtqV6aD8xPKX12Nmky5aGumnc48F5KqTSltAG4DziowDXVOQ05xF8AekRE94hoSvkNEw8UuKZ6JyKC8uuHr6WUri50PfVVSumClFLnlFI3yv8uP5ZSctRSw1JKi4B5EbFPbtVw4NUCllSffQAMiYjmuX9HhuNNhF/QuNAFFEpKaWNEnAtMpfyux5tTSq8UuKz6aChwCvByRMzOrbswpTSlgDVJ/4rvAXfkfvl/Fxhb4HrqpZTScxExGZhF+bdc/olPb/sCn9gmSVJGNeTT6ZIkZZohLklSRhnikiRllCEuSVJGGeKSJGWUIS7pXxIRhzprmlQYhrgkSRlliEsNREScHBHPR8TsiLgxN/f4yoi4Jjdn86MR0T7Xtl9EPBsRL0XE/bnnWBMRX46IaRHxYkTMiogv5brfudIc23fknrBFRFyZm0v+pYiYUKCPLtVbhrjUAERET2A0MDSl1A/YBHwbaAHMSCn1Bp4ELs295Tbgpyml/YCXK62/A7gupVRC+XOsF+bW9wfOA3oBewFDI6ItcCzQO9fPz/P7KaWGxxCXGobhwP7AC7nH3w6nPGzLgLtzbf4MfCU3Z/YuKaUnc+tvBQ6OiJZAp5TS/QAppbUppdW5Ns+nlOanlMqA2UA3YDmwFvhjRBwHfNZWUg0xxKWGIYBbU0r9cj/7pJQu20K7HX0O87pKrzcBjVNKG4HBlM/09XXgoR3sW9JWGOJSw/Ao8G8RsRtAROwaEXtS/m/Av+Xa/DvwTEppObAsIobl1p8CPJlSWgHMj4hv5vrYKSKab22HuTnkW+cmu/khUJKPDyY1ZA12FjOpIUkpvRoRFwMPR0QjYANwDrAKGJzbtpjy6+YA3wFuyIV05Zm6TgFujIgrcn2cUMVuWwJ/jYhiys8E/KiGP5bU4DmLmdSARcTKlNLOha5D0o7xdLokSRnlSFySpIxyJC5JUkYZ4pIkZZQhLklSRhnikiRllCEuSVJGGeKSJGXU/wdUmBCqFxiDKwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "R5Vnzf3I802t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct_person=0;ct_dog=0;ct_motorbike=0; ct_airplane=0; ct_car=0; ct_flower=0;"
      ],
      "metadata": {
        "id": "XfKlpx7P85kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Test/motorbike/'\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "  img = image.load_img(f1, target_size=(324, 324))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)  # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "  images = np.vstack([x])\n",
        "  classesb1 = model1.predict(images, batch_size=10)\n",
        "  classesb21 = model21.predict(images, batch_size=10)\n",
        "  #classesb22 = model22.predict(images, batch_size=10)\n",
        "  # print('bikes:',classesb1[0][0],classesb21[0])\n",
        "  if((classesb1[0][0] > .5) and (classesb21[0] < .5)):    ct_motorbike=ct_motorbike+1\n",
        "print(ct_motorbike)"
      ],
      "metadata": {
        "id": "EMeniBBD87oN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bbee4d-462f-44f5-8544-cd88625e6a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('./')\n",
        "os.chdir('/content/')\n",
        "import os\n",
        "img_dir = '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Test/airplane/' # Enter Directory of all images.\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "  img = image.load_img(f1, target_size=(324, 324))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classess1 = model1.predict(images, batch_size=10)\n",
        "  classess21 = model21.predict(images, batch_size=10)\n",
        "  #classess22 = model22.predict(images, batch_size=10)\n",
        "  # print('ships:',classess1[0][0],classess21[0])\n",
        "  if((classess1[0][0] > .5) and (classess21[0] > .5)):    ct_airplane=ct_airplane+1\n",
        "print(ct_airplane)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9LYkeUE88jG",
        "outputId": "29549fad-f954-4d80-bc75-5b06f1fa4e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('./')\n",
        "os.chdir('/content/')\n",
        "import os\n",
        "img_dir = '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Test/car/' # Enter Directory of all images.\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "  img = image.load_img(f1, target_size=(324, 324))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classest1 = model1.predict(images, batch_size=10)\n",
        "  #classest21 = model21.predict(images, batch_size=10)\n",
        "  classest22 = model22.predict(images, batch_size=10)\n",
        "  # print('tracs:',classest1[0][1],classest22[0])\n",
        "  if((classest1[0][1] > .5) and (classest22[0] > .5)):    ct_car=ct_car+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-BfaiOr9BS0",
        "outputId": "bda75dd5-54a9-4fb6-ee31-8ce56506d95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ct_car)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoDm2Yv5DU_Q",
        "outputId": "3225332d-1bde-4887-efc3-c6f8e69a16a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('./')\n",
        "os.chdir('/content/')\n",
        "import os\n",
        "img_dir = '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Test/flower/' # Enter Directory of all images.\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "  img = image.load_img(f1, target_size=(324, 324))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classesw1 = model1.predict(images, batch_size=10)\n",
        "  #classesw21 = model21.predict(images, batch_size=10)\n",
        "  classesw22 = model22.predict(images, batch_size=10)\n",
        "  # print('wagons:',classesw1[0][1],classesw22[0])\n",
        "  if((classesw1[0][1] > .5) and (classesw22[0] < .5)):    ct_flower=ct_flower+1\n",
        "print(ct_flower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtElvknU9FsO",
        "outputId": "9e435a71-04db-49c5-fab8-0324458dfff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "wagons: 0.9999567 [8.627005e-34]\n",
            "wagons: 0.9953053 [8.6468887e-23]\n",
            "wagons: 0.99999475 [1.3500795e-37]\n",
            "wagons: 0.9999846 [7.924458e-30]\n",
            "wagons: 0.6999797 [1.7306759e-29]\n",
            "wagons: 0.999801 [1.9373548e-30]\n",
            "wagons: 0.9999901 [2.5926018e-33]\n",
            "wagons: 0.9999974 [4.8509772e-33]\n",
            "wagons: 0.9999417 [1.899508e-28]\n",
            "wagons: 0.99997187 [8.742057e-35]\n",
            "wagons: 0.97212344 [2.785618e-18]\n",
            "wagons: 0.9999988 [0.]\n",
            "wagons: 0.9903632 [7.0594985e-27]\n",
            "wagons: 0.9999957 [1.005913e-34]\n",
            "wagons: 0.998315 [4.0653534e-29]\n",
            "wagons: 0.9998889 [1.0956597e-33]\n",
            "wagons: 0.99999034 [1.81868e-36]\n",
            "wagons: 0.9999591 [2.6774108e-33]\n",
            "wagons: 0.2841296 [5.1193768e-17]\n",
            "wagons: 0.99999964 [0.]\n",
            "wagons: 0.9999292 [2.2239325e-25]\n",
            "wagons: 0.99541014 [2.6948612e-18]\n",
            "wagons: 0.99931645 [3.9294333e-24]\n",
            "wagons: 0.9995751 [2.1524449e-17]\n",
            "wagons: 0.99942434 [7.994086e-28]\n",
            "wagons: 0.99702007 [1.698562e-21]\n",
            "wagons: 0.99996626 [0.]\n",
            "wagons: 0.9993229 [6.457309e-35]\n",
            "wagons: 0.99999034 [0.]\n",
            "wagons: 0.9998241 [7.0741876e-35]\n",
            "wagons: 0.9999924 [0.]\n",
            "wagons: 0.9999963 [0.]\n",
            "wagons: 0.99999607 [1.3703866e-32]\n",
            "wagons: 0.99998367 [6.407037e-34]\n",
            "wagons: 0.9984189 [3.8395854e-21]\n",
            "wagons: 0.9999585 [6.6890165e-30]\n",
            "wagons: 0.99997425 [6.314971e-28]\n",
            "wagons: 0.99928516 [9.011883e-29]\n",
            "wagons: 0.99999654 [1.06403655e-36]\n",
            "wagons: 0.9999032 [6.312356e-25]\n",
            "wagons: 0.999995 [0.]\n",
            "wagons: 0.99999774 [0.]\n",
            "wagons: 0.9999858 [1.1562612e-29]\n",
            "wagons: 0.9992716 [4.1067448e-25]\n",
            "wagons: 0.9999863 [0.]\n",
            "wagons: 0.9999918 [2.2311144e-31]\n",
            "wagons: 0.99994266 [5.288731e-27]\n",
            "wagons: 0.99920243 [1.9865594e-17]\n",
            "wagons: 0.9999968 [1.8291224e-37]\n",
            "wagons: 0.9997676 [1.5074231e-35]\n",
            "wagons: 0.96939474 [6.3521345e-34]\n",
            "wagons: 0.99798405 [4.238464e-33]\n",
            "wagons: 0.99998856 [3.6738345e-36]\n",
            "wagons: 0.97967565 [9.223712e-25]\n",
            "wagons: 0.99859875 [4.398864e-22]\n",
            "wagons: 0.9999906 [4.1593572e-32]\n",
            "wagons: 0.999985 [1.3499086e-31]\n",
            "wagons: 0.99999654 [2.505851e-38]\n",
            "wagons: 0.99999106 [5.8172097e-33]\n",
            "wagons: 0.9999964 [2.9184437e-34]\n",
            "wagons: 0.9999987 [0.]\n",
            "wagons: 0.99999774 [4.2247063e-35]\n",
            "wagons: 0.84626997 [2.4188966e-24]\n",
            "wagons: 0.9999827 [9.905919e-38]\n",
            "wagons: 0.99998176 [1.1127562e-34]\n",
            "wagons: 0.99999726 [5.073944e-38]\n",
            "wagons: 0.9999981 [0.]\n",
            "wagons: 0.99998856 [8.8118605e-36]\n",
            "wagons: 0.9999734 [1.04353234e-35]\n",
            "wagons: 0.9984781 [3.6503052e-31]\n",
            "wagons: 0.98505175 [8.306427e-33]\n",
            "wagons: 0.99999905 [0.]\n",
            "wagons: 0.99999714 [0.]\n",
            "wagons: 0.99999464 [2.7563452e-28]\n",
            "wagons: 0.9999844 [4.3119212e-38]\n",
            "wagons: 0.9999908 [6.151784e-37]\n",
            "wagons: 0.99995434 [1.4549156e-35]\n",
            "wagons: 0.9996718 [5.4442192e-28]\n",
            "wagons: 0.9999945 [1.9124732e-34]\n",
            "wagons: 0.99989295 [2.0136654e-34]\n",
            "wagons: 0.9999988 [0.]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.99998415 [9.963478e-32]\n",
            "wagons: 0.9997389 [1.9914308e-24]\n",
            "wagons: 0.999995 [2.1074006e-33]\n",
            "wagons: 0.9999478 [4.9726875e-33]\n",
            "wagons: 0.9999223 [2.0628164e-36]\n",
            "wagons: 0.9999844 [1.791065e-28]\n",
            "wagons: 0.99996424 [2.1825327e-32]\n",
            "wagons: 0.5922637 [2.8552364e-18]\n",
            "wagons: 0.9993051 [2.1727041e-26]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.99999905 [0.]\n",
            "wagons: 0.99990773 [0.]\n",
            "wagons: 0.9995435 [1.5842646e-24]\n",
            "wagons: 0.99889576 [1.0668406e-29]\n",
            "wagons: 0.2855205 [0.08896579]\n",
            "wagons: 0.99813616 [4.0035974e-27]\n",
            "wagons: 0.9999976 [8.583367e-37]\n",
            "wagons: 0.9999883 [4.985163e-34]\n",
            "wagons: 0.9999517 [1.2945066e-29]\n",
            "wagons: 0.99998724 [3.9988463e-29]\n",
            "wagons: 0.9999989 [0.]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.9999881 [2.7952266e-28]\n",
            "wagons: 0.99932814 [3.605179e-30]\n",
            "wagons: 0.9999999 [9.57164e-37]\n",
            "wagons: 0.9999988 [0.]\n",
            "wagons: 0.9996834 [6.078384e-34]\n",
            "wagons: 0.96220994 [7.236973e-21]\n",
            "wagons: 0.99999654 [5.412417e-34]\n",
            "wagons: 0.99973947 [3.4139491e-25]\n",
            "wagons: 0.99991596 [8.711069e-34]\n",
            "wagons: 0.99999857 [3.2564937e-33]\n",
            "wagons: 0.99964666 [6.775801e-36]\n",
            "wagons: 0.9999944 [1.8906082e-29]\n",
            "wagons: 0.99817693 [3.3667156e-19]\n",
            "wagons: 0.99979836 [2.7263014e-28]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.9999802 [1.6921415e-27]\n",
            "wagons: 0.9999211 [2.7553317e-31]\n",
            "wagons: 0.99997747 [2.1504484e-34]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.9999732 [2.506023e-38]\n",
            "wagons: 0.9999999 [2.3025879e-38]\n",
            "wagons: 0.9967998 [5.176368e-23]\n",
            "wagons: 0.99999285 [8.842281e-33]\n",
            "wagons: 0.9999757 [5.853499e-31]\n",
            "wagons: 0.9988776 [3.863255e-28]\n",
            "wagons: 0.99966013 [4.7944335e-22]\n",
            "wagons: 0.99998295 [2.8791187e-29]\n",
            "wagons: 0.9999956 [0.]\n",
            "wagons: 0.9999975 [0.]\n",
            "wagons: 0.9999628 [0.]\n",
            "wagons: 0.997221 [1.6951266e-19]\n",
            "wagons: 0.9999982 [9.3758526e-35]\n",
            "wagons: 0.9999913 [1.2829639e-36]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.98609215 [2.210282e-25]\n",
            "wagons: 0.99999213 [1.7949702e-36]\n",
            "wagons: 0.99940574 [5.4560937e-27]\n",
            "wagons: 0.9999981 [4.61375e-38]\n",
            "wagons: 1.0 [0.]\n",
            "wagons: 0.9999995 [0.]\n",
            "wagons: 0.9999999 [0.]\n",
            "wagons: 0.99968576 [6.5524516e-33]\n",
            "wagons: 0.99999 [4.0324693e-37]\n",
            "wagons: 0.99998343 [4.8829787e-28]\n",
            "wagons: 0.9999988 [1.20966415e-36]\n",
            "wagons: 0.9989766 [4.4131976e-16]\n",
            "wagons: 0.9999969 [4.25921e-33]\n",
            "wagons: 0.9992355 [2.9059195e-22]\n",
            "wagons: 0.9999833 [4.3190413e-34]\n",
            "wagons: 0.9997297 [2.0614134e-31]\n",
            "wagons: 0.9999869 [3.732962e-33]\n",
            "wagons: 0.99947625 [3.2329698e-22]\n",
            "wagons: 0.9999161 [0.]\n",
            "wagons: 0.99998105 [2.0439792e-35]\n",
            "wagons: 0.99979347 [8.6252734e-24]\n",
            "wagons: 0.99999917 [0.]\n",
            "wagons: 0.99998045 [1.8216994e-37]\n",
            "wagons: 0.9999931 [6.93804e-30]\n",
            "wagons: 0.87766415 [1.823013e-15]\n",
            "wagons: 0.99997973 [0.]\n",
            "wagons: 0.9999856 [2.9685413e-36]\n",
            "164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('./')\n",
        "os.chdir('/content/')\n",
        "import os\n",
        "img_dir = '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Test/dog/' # Enter Directory of all images.\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "  img = image.load_img(f1, target_size=(324, 324))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classesw1 = model1.predict(images, batch_size=10)\n",
        "  #classesw21 = model21.predict(images, batch_size=10)\n",
        "  classesw23 = model23.predict(images, batch_size=10)\n",
        "  #print('cats:',classesw1[0][2],classesw23[0])\n",
        "  if((classesw1[0][2] > .5) and (classesw23[0] > .5)):    ct_dog=ct_dog+1\n",
        "print(ct_dog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCAuWA989GbF",
        "outputId": "5ef2943d-04a0-47ac-8cd4-2ef52f164832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('./')\n",
        "os.chdir('/content/')\n",
        "import os\n",
        "img_dir = '/content/drive/MyDrive/Colab Notebooks/Train Data For selected 2 project/natural_images/N/Test/chris_evans/' # Enter Directory of all images.\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "data_path = os. path. join(img_dir,'*g')\n",
        "files = glob. glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "  img = image.load_img(f1, target_size=(324, 324))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classesw1 = model1.predict(images, batch_size=10)\n",
        "  #classesw21 = model21.predict(images, batch_size=10)\n",
        "  classesw23 = model23.predict(images, batch_size=10)\n",
        "  print('person:',classesw1[0][2],classesw23[0])\n",
        "  if((classesw1[0][2] > .5) and (classesw23[0] < .5)):    ct_person=ct_person+1\n",
        "print(ct_person)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn328_N59I20",
        "outputId": "4e296fe5-9767-4ac5-de8b-2dafce65d0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "dogs: 1.0 [2.5919607e-13]\n",
            "dogs: 1.0 [7.5794094e-05]\n",
            "dogs: 1.0 [4.4588098e-09]\n",
            "dogs: 1.0 [3.4044714e-08]\n",
            "dogs: 1.0 [1.13581075e-10]\n",
            "dogs: 1.0 [2.1086072e-10]\n",
            "dogs: 1.0 [0.21105362]\n",
            "dogs: 1.0 [1.0548226e-09]\n",
            "dogs: 1.0 [2.8795673e-15]\n",
            "dogs: 1.0 [1.1280889e-12]\n",
            "dogs: 1.0 [5.596455e-05]\n",
            "dogs: 1.0 [5.2798467e-14]\n",
            "dogs: 0.00010424631 [0.99999356]\n",
            "dogs: 0.0012218894 [0.00055785]\n",
            "dogs: 1.0 [2.6977958e-12]\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct_total=ct_motorbike+ct_airplane+ct_car+ct_flower+ct_person+ct_dog"
      ],
      "metadata": {
        "id": "oNGIpPI49K67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total = ',ct_total)\n",
        "print('Breakup = ',ct_person,ct_dog,ct_motorbike, ct_airplane, ct_car, ct_flower)  \n",
        "print('accuracy=',ct_total/977) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuRBxsSu9Oe2",
        "outputId": "23cfc4f6-bb27-464f-dac2-958b38161ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total =  967\n",
            "Breakup =  168 166 164 164 139 166\n",
            "accuracy= 0.9897645854657113\n"
          ]
        }
      ]
    }
  ]
}