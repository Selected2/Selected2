{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaturalImages_4C_baseline_resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#4 Class-Classification\n",
        "## Natural Image\n",
        "## first model  >>  baseline_resnet50\n"
      ],
      "metadata": {
        "id": "ilpe7CHkFY0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "import cv2"
      ],
      "metadata": {
        "id": "GGBEJWIXF9K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kDy3pOhQFwPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd1686f-3075-4b75-e806-331b15505187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa7iAsiVFQYr"
      },
      "outputs": [],
      "source": [
        "img_rows, img_cols = 224, 224 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\t# return the image\n",
        "\treturn image"
      ],
      "metadata": {
        "id": "SvE-OWHYF5ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%clear base_model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "#valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)   \n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "\n",
        "train_generator1 = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Dataset/Train/',\n",
        "        classes=['airplane','motorbike','car','person'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')\n",
        "\n",
        "valid_generator1 = valid_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Dataset/Validate/',\n",
        "        classes=['airplane','motorbike','car','person'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')\n"
      ],
      "metadata": {
        "id": "VFMtqdtjMIdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466d0abf-eb27-4345-e414-aaaf09574c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1532 images belonging to 4 classes.\n",
            "Found 707 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model1 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)"
      ],
      "metadata": {
        "id": "gztmLI0fMJZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model1.layers:   layer.trainable = False"
      ],
      "metadata": {
        "id": "DBSGUOxkMLPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model1.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "preds = tf.keras.layers.Dense(4, activation ='softmax')(x)\n",
        "\n",
        "model1 = tf.keras.models.Model(inputs=base_model1.input, outputs=preds)\n"
      ],
      "metadata": {
        "id": "-2ow0eKhMRNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "lDMhUyVBMUCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(\n",
        "      train_generator1,\n",
        "      steps_per_epoch=train_generator1.n//train_generator1.batch_size,\n",
        "      epochs=4,\n",
        "      validation_data=valid_generator1,\n",
        "      validation_steps=25)"
      ],
      "metadata": {
        "id": "SB4tSlzrMYUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf35bc8-78ea-4785-9a2a-e3ce2b9a1b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "47/47 [==============================] - ETA: 0s - loss: 1.2428 - accuracy: 0.8967WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 25 batches). You may need to use the repeat() function when building your dataset.\n",
            "47/47 [==============================] - 380s 8s/step - loss: 1.2428 - accuracy: 0.8967 - val_loss: 4.3823e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/4\n",
            "47/47 [==============================] - 233s 5s/step - loss: 8.0005e-06 - accuracy: 1.0000\n",
            "Epoch 3/4\n",
            "47/47 [==============================] - 233s 5s/step - loss: 7.0753e-07 - accuracy: 1.0000\n",
            "Epoch 4/4\n",
            "47/47 [==============================] - 233s 5s/step - loss: 4.5379e-08 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator #, array_to_img, img_to_array, load_img\n",
        "\n",
        "model1.save('/content/drive/My Drive/db/m1.h5') \n",
        "\n",
        "'''\n",
        "model1 = tf.keras.models.load_model('m1.h5')\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "IdLAvDoaMakm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c30d9f1-98cb-4b13-f0eb-d1549e811d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel1 = tf.keras.models.load_model('m1.h5')\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ntest_total = 745, accuracy_% = 0.9168\n",
        "# classified = 683\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = valid_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Dataset/Test',\n",
        "        classes=['airplane','motorbike','car','person'],\n",
        "        target_size=(img_rows, img_cols),batch_size=32,class_mode='categorical')"
      ],
      "metadata": {
        "id": "hKuxlxsZMeFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7daafa-111f-41b9-b305-5bc78b9645fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 669 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model1.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "UbZMpuD9Mg1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00254e03-5d45-4082-f5b1-ba551e47a8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 113s 5s/step - loss: 0.0312 - accuracy: 0.9985\n"
          ]
        }
      ]
    }
  ]
}